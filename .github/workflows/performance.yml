name: Performance Testing

on: [push, pull_request, schedule]

jobs:
  performance:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10"]
    
    services:
      chrome:
        image: selenium/standalone-chrome:latest
        ports:
          - 4444:4444
        options: >-
          --health-cmd "/opt/bin/health-check.sh"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler psutil
        pip install -e .
    
    - name: Run performance benchmarks
      run: |
        python -m pytest tests/performance/ -v --benchmark-only --benchmark-sort=mean
    
    - name: Run memory profiling
      run: |
        python -m memory_profiler pi-pages.py --dry-run --max-visits 10
    
    - name: Run load test
      run: |
        python -m pytest tests/load/ -v --timeout=600
    
    - name: Generate performance report
      run: |
        echo "## Performance Test Results" > performance-report.md
        echo "" >> performance-report.md
        echo "### Memory Usage" >> performance-report.md
        echo "- Peak memory usage: $(grep 'Peak memory' memory_profile.log | tail -1 || echo 'N/A')" >> performance-report.md
        echo "" >> performance-report.md
        echo "### Benchmark Results" >> performance-report.md
        if [ -f ".benchmarks/*/machine_info.json" ]; then
          echo "- Benchmark data available in artifacts" >> performance-report.md
        fi
    
    - name: Upload performance artifacts
      uses: actions/upload-artifact@v3
      with:
        name: performance-results-${{ matrix.python-version }}
        path: |
          .benchmarks/
          memory_profile.log
          performance-report.md
    
    - name: Comment performance results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          let comment = '## Performance Test Results\n\n';
          
          try {
            const report = fs.readFileSync('performance-report.md', 'utf8');
            comment += report;
          } catch (e) {
            comment += 'Performance tests completed. Check artifacts for detailed results.';
          }
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          }); 